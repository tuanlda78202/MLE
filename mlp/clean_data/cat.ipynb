{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. One Hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this encoding, a \"dictionary\" needs to be constructed containing all possible values of each item data. Each item value is then encoded with a binary vector with all zeroes minus an element equal to 1 corresponding to the item value's position in the dictionary.\n",
    "\n",
    "For example, if we have one-column data `\"Sydney\", \"Paris\", \"New York\"` then we do the following steps:\n",
    "\n",
    "1. Build a dictionary. In this case, we can build the dictionary as `[\"New York\", \"Paris\", \"Sydney\"]`\n",
    "\n",
    "2. After building the dictionary, we need to save the index of each item in the dictionary. With the above dictionary, the corresponding index is `\"New York\": 0, \"Paris\": 1, \"Sydney\": 2`.\n",
    "\n",
    "3. Finally, we encode the initial values as follows:\n",
    "\n",
    "| Cat | One-hot Encoder |\n",
    "| --- | --- |\n",
    "| `\"Sydney\"` | `[0, 0, 1]` |\n",
    "| `\"Paris\"` | `[0, 1, 0]`|\n",
    "|`\"New York\"` | `[1, 0, 0]`|\n",
    "\n",
    "\n",
    "Since each item value is encoded with a vector with only one element equal to 1 at its corresponding position in the dictionary, this vector is called a \"one-hot vector\". The dimension of this vector is precisely similar to the number of words in the dictionary. To put it another way, each binary value in this vector represents whether the item value in question \"is\" the corresponding value in the dictionary. With out-of-vocabulary or OOV, we can encode them as `[0, 0, 0]` in the sense that they are not any dictionary values.\n",
    "\n",
    "Another common way to encode values ​​that are not in the dictionary is to add the word `\"unknown\"` to the dictionary, and all new values ​​are grouped into this `\"unknown\"`. It should be noted when `\"unknown\"` is also a possible value in the dataset. Encoding unknown values ​​with the same vector can confuse the model that these two values ​​are the same. Suppose somehow you know these values ​​appear a lot in the future. In that case, you should specifically include them in the dictionary to have your encoding to avoid duplication with other discounts. If these values ​​occur rarely, we can put them together in a code and consider them to be exact as \"rare\". Trying to encode each rare value will result in a lot of memory and a more complex model to learn in particular cases, where overfitting is more likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Sklearn\n",
    "[`sklearn.preprocessing.OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn-preprocessing-onehotencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paris</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City  Population\n",
       "0    Sydney          10\n",
       "1     Paris          59\n",
       "2  New York          89"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data = {\"City\": [\"Sydney\", \"Paris\", \"New York\"], \"Population\" : [10, 59, 89]}\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 2)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHotEncoder()\n",
    "\n",
    "onehot_encoded_city= onehot.fit_transform(df[[\"City\"]])\n",
    "print(type(onehot_encoded_city))\n",
    "print(onehot_encoded_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few points to note here. First, the default `onehot_encoded_location` return is stored as [`scipy.sparse.csr.csr_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) is a special type for storing two-dimensional arrays with mostly zero elements. This storage is very convenient in terms of memory because each vector has exactly one non-zero element. If the dictionary size grows into the millions and we store the matrix in its common form, it will be a waste of resources to store a lot of zeros that don't carry much information.\n",
    "\n",
    "When printing `onehot_encoded_location,` we will see two columns. The first column is the coordinates of the non-zero points, and the second column is the value of the element at that coordinate - always equal to 1 in this case.\n",
    "\n",
    "To return the result in standard matrix form, we can add `sparse=False` at initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHotEncoder(sparse=False)\n",
    "\n",
    "onehot_encoded_city= onehot.fit_transform(df[[\"City\"]])\n",
    "print(onehot_encoded_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['New York', 'Paris', 'Sydney'], dtype=object)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding is a way of rapidly converting item data to digital form. With this coding, we can quickly build simple models such as linear regression or SVM, requiring the input value to be numeric. With decision tree models (Random Forest, LightGBM, XGBoost, etc.) - which are very common with tabular data, we don't need to convert them to one-hot; we just need to return them to dictionary ordinal numbers and report to model that it is item-specific, the models will have appropriate processing \n",
    "\n",
    "See also [`sklearn.preprocessing.LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hashing\n",
    "Comming soon..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Crossing\n",
    "Comming soon..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "618af10fdd433c84be79e5d9cef7a85d74ad68be7e2e9dd9461a47b527f16862"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
